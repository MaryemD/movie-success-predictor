{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02 - Preprocessing & Feature Engineering\n",
    "\n",
    "**Objective:** Clean, filter, and create **4 processed datasets** with different data source combinations.\n",
    "\n",
    "---\n",
    "\n",
    "**4 Datasets Produced:**\n",
    "\n",
    "| Dataset | Sources | Key |\n",
    "|---|---|---|\n",
    "| `movies_processed_metadata.csv` | movies_metadata only | `metadata` |\n",
    "| `movies_processed_meta_credits.csv` | movies_metadata + credits | `meta_credits` |\n",
    "| `movies_processed_meta_keywords.csv` | movies_metadata + keywords | `meta_keywords` |\n",
    "| `movies_processed.csv` | all three combined | `all` |\n",
    "\n",
    "**Preprocessing:**\n",
    "1. Load & parse JSON columns in all 3 raw datasets\n",
    "2. Type conversions, drop corrupted rows (non-numeric IDs)\n",
    "3. Remove duplicates from all 3 datasets\n",
    "4. Filter: Released status, budget > 0, revenue > 0, vote_count > 0\n",
    "\n",
    "**Feature Engineering (applied to base metadata before merging):**\n",
    "5. Binary: `is_collection`, `is_english`\n",
    "6. Temporal: `release_year`, `release_month`\n",
    "7. Financial: `roi` (replaces raw revenue)\n",
    "8. Counts: `num_genres`, `num_production_companies`, etc.\n",
    "9. `primary_genre` categorical\n",
    "\n",
    "**Additional Features (for datasets with credits):**\n",
    "10. `num_cast`, `num_crew`\n",
    "11. Top modern directors & actors binary features\n",
    "\n",
    "**Additional Features (for datasets with keywords):**\n",
    "12. `num_keywords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_metadata : 45,466 rows x 24 cols\n",
      "credits         : 45,476 rows x 3 cols\n",
      "keywords        : 46,419 rows x 2 cols\n"
     ]
    }
   ],
   "source": [
    "# Load all three raw datasets\n",
    "movies_df = pd.read_csv('../data/raw/movies_metadata.csv', low_memory=False)\n",
    "credits_df = pd.read_csv('../data/raw/credits.csv')\n",
    "keywords_df = pd.read_csv('../data/raw/keywords.csv')\n",
    "\n",
    "print(f'movies_metadata : {movies_df.shape[0]:,} rows x {movies_df.shape[1]} cols')\n",
    "print(f'credits         : {credits_df.shape[0]:,} rows x {credits_df.shape[1]} cols')\n",
    "print(f'keywords        : {keywords_df.shape[0]:,} rows x {keywords_df.shape[1]} cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing JSON columns...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# JSON parser for stringified list-of-dicts columns\n",
    "def parse_json_column(val):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return json.loads(val)\n",
    "        except Exception:\n",
    "            try:\n",
    "                parsed = literal_eval(val)\n",
    "                return parsed if isinstance(parsed, list) else []\n",
    "            except Exception:\n",
    "                return []\n",
    "    return val if isinstance(val, list) else []\n",
    "\n",
    "# Parse movies JSON columns\n",
    "print('Parsing JSON columns...')\n",
    "for col in ['genres', 'production_companies', 'production_countries', 'spoken_languages']:\n",
    "    movies_df[col] = movies_df[col].apply(parse_json_column)\n",
    "\n",
    "# Parse credits JSON columns\n",
    "credits_df['cast_parsed'] = credits_df['cast'].apply(parse_json_column)\n",
    "credits_df['crew_parsed'] = credits_df['crew'].apply(parse_json_column)\n",
    "\n",
    "# Parse keywords\n",
    "keywords_df['keywords_parsed'] = keywords_df['keywords'].apply(parse_json_column)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rows: 45,466\n",
      "After type cleanup: 45,463  (dropped 3 corrupted rows)\n"
     ]
    }
   ],
   "source": [
    "# 2.1  Type conversions + drop corrupted rows\n",
    "n_start = len(movies_df)\n",
    "print(f'Starting rows: {n_start:,}')\n",
    "\n",
    "# Drop rows with non-numeric IDs (3 corrupted rows found in EDA)\n",
    "movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
    "movies_df = movies_df.dropna(subset=['id'])\n",
    "movies_df['id'] = movies_df['id'].astype(int)\n",
    "\n",
    "# Convert numeric columns stored as strings\n",
    "movies_df['budget'] = pd.to_numeric(movies_df['budget'], errors='coerce')\n",
    "movies_df['popularity'] = pd.to_numeric(movies_df['popularity'], errors='coerce')\n",
    "movies_df['revenue'] = pd.to_numeric(movies_df['revenue'], errors='coerce')\n",
    "movies_df['runtime'] = pd.to_numeric(movies_df['runtime'], errors='coerce')\n",
    "movies_df['vote_average'] = pd.to_numeric(movies_df['vote_average'], errors='coerce')\n",
    "movies_df['vote_count'] = pd.to_numeric(movies_df['vote_count'], errors='coerce')\n",
    "\n",
    "# Parse release date\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')\n",
    "\n",
    "n_after = len(movies_df)\n",
    "print(f'After type cleanup: {n_after:,}  (dropped {n_start - n_after:,} corrupted rows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Removing duplicates ---\n",
      "Movies:   45,463 -> 45,433  (dropped 30)\n",
      "Credits:  45,476 -> 45,432  (dropped 44)\n",
      "Keywords: 46,419 -> 45,432  (dropped 987)\n"
     ]
    }
   ],
   "source": [
    "# 2.2  Remove duplicates from all 3 datasets\n",
    "print('--- Removing duplicates ---')\n",
    "\n",
    "n1 = len(movies_df)\n",
    "movies_df = movies_df.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f'Movies:   {n1:,} -> {len(movies_df):,}  (dropped {n1 - len(movies_df):,})')\n",
    "\n",
    "n2 = len(credits_df)\n",
    "credits_df = credits_df.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f'Credits:  {n2:,} -> {len(credits_df):,}  (dropped {n2 - len(credits_df):,})')\n",
    "\n",
    "n3 = len(keywords_df)\n",
    "keywords_df = keywords_df.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f'Keywords: {n3:,} -> {len(keywords_df):,}  (dropped {n3 - len(keywords_df):,})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Filtering movies ---\n",
      "Start: 45,433\n",
      "After status=Released: 44,985\n",
      "After budget>0 & revenue>0: 5,371\n",
      "After vote_count>0: 5,364\n",
      "After valid runtime: 5,352\n",
      "Final after all filters: 5,352\n"
     ]
    }
   ],
   "source": [
    "# 2.3  Filter movies\n",
    "print('--- Filtering movies ---')\n",
    "print(f'Start: {len(movies_df):,}')\n",
    "\n",
    "# Keep only Released movies\n",
    "movies_df = movies_df[movies_df['status'] == 'Released']\n",
    "print(f'After status=Released: {len(movies_df):,}')\n",
    "\n",
    "# Remove movies with budget <= 0 or revenue <= 0 (corrupted/missing financial data)\n",
    "movies_df = movies_df[(movies_df['budget'] > 0) & (movies_df['revenue'] > 0)]\n",
    "print(f'After budget>0 & revenue>0: {len(movies_df):,}')\n",
    "\n",
    "# Remove entries with 0 vote_count\n",
    "movies_df = movies_df[movies_df['vote_count'] > 0]\n",
    "print(f'After vote_count>0: {len(movies_df):,}')\n",
    "\n",
    "# Handle runtime: drop zeros, fill NaN with median\n",
    "movies_df = movies_df[movies_df['runtime'] > 0]\n",
    "med_runtime = movies_df['runtime'].median()\n",
    "movies_df['runtime'] = movies_df['runtime'].fillna(med_runtime)\n",
    "print(f'After valid runtime: {len(movies_df):,}')\n",
    "\n",
    "# Drop missing release dates\n",
    "movies_df = movies_df.dropna(subset=['release_date'])\n",
    "print(f'Final after all filters: {len(movies_df):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Base Feature Engineering (Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Binary Features ---\n",
      "is_collection: 1,220 / 5,352\n",
      "is_english:    4,783 / 5,352\n",
      "\n",
      "--- Temporal Features ---\n",
      "Year range: 1915 – 2017\n",
      "\n",
      "--- Financial Feature: ROI ---\n",
      "ROI median=106.7%, mean=559504.6%\n",
      "Profitable (ROI>0): 3,743 / 5,352\n",
      "\n",
      "--- Count Features (Metadata) ---\n",
      "       num_genres  num_production_companies  num_production_countries  num_spoken_languages\n",
      "count      5352.0                    5352.0                    5352.0                5352.0\n",
      "mean          2.6                       2.9                       1.4                   1.5\n",
      "std           1.1                       2.2                       0.8                   0.9\n",
      "min           0.0                       0.0                       0.0                   0.0\n",
      "25%           2.0                       1.0                       1.0                   1.0\n",
      "50%           3.0                       2.0                       1.0                   1.0\n",
      "75%           3.0                       4.0                       2.0                   2.0\n",
      "max           8.0                      26.0                      12.0                   9.0\n",
      "\n",
      "--- Primary Genre ---\n",
      "Unique genres: 21\n",
      "primary_genre\n",
      "Drama        1306\n",
      "Comedy       1061\n",
      "Action        958\n",
      "Adventure     413\n",
      "Horror        325\n"
     ]
    }
   ],
   "source": [
    "# 3.1  Binary, temporal, financial & count features from metadata\n",
    "\n",
    "print('--- Binary Features ---')\n",
    "movies_df['is_collection'] = movies_df['belongs_to_collection'].apply(\n",
    "    lambda x: 0 if pd.isna(x) or x == '' else 1)\n",
    "movies_df['is_english'] = (movies_df['original_language'] == 'en').astype(int)\n",
    "print(f'is_collection: {movies_df[\"is_collection\"].sum():,} / {len(movies_df):,}')\n",
    "print(f'is_english:    {movies_df[\"is_english\"].sum():,} / {len(movies_df):,}')\n",
    "\n",
    "print('\\n--- Temporal Features ---')\n",
    "movies_df['release_year'] = movies_df['release_date'].dt.year.astype(int)\n",
    "movies_df['release_month'] = movies_df['release_date'].dt.month.astype(int)\n",
    "print(f'Year range: {movies_df[\"release_year\"].min()} – {movies_df[\"release_year\"].max()}')\n",
    "\n",
    "print('\\n--- Financial Feature: ROI ---')\n",
    "movies_df['roi'] = ((movies_df['revenue'] - movies_df['budget']) / movies_df['budget'] * 100).round(2)\n",
    "movies_df = movies_df.drop(columns=['revenue'])\n",
    "print(f'ROI median={movies_df[\"roi\"].median():.1f}%, mean={movies_df[\"roi\"].mean():.1f}%')\n",
    "print(f'Profitable (ROI>0): {(movies_df[\"roi\"]>0).sum():,} / {len(movies_df):,}')\n",
    "\n",
    "print('\\n--- Count Features (Metadata) ---')\n",
    "movies_df['num_genres'] = movies_df['genres'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "movies_df['num_production_companies'] = movies_df['production_companies'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "movies_df['num_production_countries'] = movies_df['production_countries'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "movies_df['num_spoken_languages'] = movies_df['spoken_languages'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "count_cols = ['num_genres', 'num_production_companies', 'num_production_countries', 'num_spoken_languages']\n",
    "print(movies_df[count_cols].describe().round(1).to_string())\n",
    "\n",
    "print('\\n--- Primary Genre ---')\n",
    "def get_primary_genre(genres_list):\n",
    "    if isinstance(genres_list, list) and len(genres_list) > 0:\n",
    "        return genres_list[0].get('name', 'Unknown')\n",
    "    return 'Unknown'\n",
    "\n",
    "movies_df['primary_genre'] = movies_df['genres'].apply(get_primary_genre)\n",
    "print(f'Unique genres: {movies_df[\"primary_genre\"].nunique()}')\n",
    "print(movies_df['primary_genre'].value_counts().head(5).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create 4 Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credits features ready: 45,432 rows\n",
      "Keywords features ready: 45,432 rows\n",
      "\n",
      "--- Creating 4 datasets ---\n",
      "1. Metadata only:         5,352 rows\n",
      "2. Metadata + Credits:    5,352 rows (lost 0)\n",
      "3. Metadata + Keywords:   5,352 rows (lost 0)\n",
      "4. All Combined:          5,352 rows (lost 0)\n"
     ]
    }
   ],
   "source": [
    "# 4.1  Prepare credits features\n",
    "credits_merge = credits_df[['id', 'cast_parsed', 'crew_parsed']].copy()\n",
    "credits_merge['id'] = pd.to_numeric(credits_merge['id'], errors='coerce')\n",
    "credits_merge = credits_merge.dropna(subset=['id'])\n",
    "credits_merge['id'] = credits_merge['id'].astype(int)\n",
    "credits_merge['num_cast'] = credits_merge['cast_parsed'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "credits_merge['num_crew'] = credits_merge['crew_parsed'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "print(f'Credits features ready: {len(credits_merge):,} rows')\n",
    "\n",
    "# 4.2  Prepare keywords features\n",
    "keywords_merge = keywords_df[['id', 'keywords_parsed']].copy()\n",
    "keywords_merge['id'] = pd.to_numeric(keywords_merge['id'], errors='coerce')\n",
    "keywords_merge = keywords_merge.dropna(subset=['id'])\n",
    "keywords_merge['id'] = keywords_merge['id'].astype(int)\n",
    "keywords_merge['num_keywords'] = keywords_merge['keywords_parsed'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "print(f'Keywords features ready: {len(keywords_merge):,} rows')\n",
    "\n",
    "# 4.3  Create 4 datasets by merging different combinations\n",
    "print('\\n--- Creating 4 datasets ---')\n",
    "\n",
    "# Dataset 1: Metadata Only\n",
    "df_metadata = movies_df.copy()\n",
    "print(f'1. Metadata only:         {len(df_metadata):,} rows')\n",
    "\n",
    "# Dataset 2: Metadata + Credits\n",
    "df_meta_credits = movies_df.merge(credits_merge, on='id', how='inner')\n",
    "print(f'2. Metadata + Credits:    {len(df_meta_credits):,} rows (lost {len(movies_df) - len(df_meta_credits):,})')\n",
    "\n",
    "# Dataset 3: Metadata + Keywords\n",
    "df_meta_keywords = movies_df.merge(keywords_merge, on='id', how='inner')\n",
    "print(f'3. Metadata + Keywords:   {len(df_meta_keywords):,} rows (lost {len(movies_df) - len(df_meta_keywords):,})')\n",
    "\n",
    "# Dataset 4: All Combined\n",
    "df_all = movies_df.merge(credits_merge, on='id', how='inner')\n",
    "df_all = df_all.merge(keywords_merge, on='id', how='inner')\n",
    "print(f'4. All Combined:          {len(df_all):,} rows (lost {len(movies_df) - len(df_all):,})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_credits: has_top_director=475, has_top_actor=1184\n",
      "all: has_top_director=475, has_top_actor=1184\n",
      "\n",
      "Top 10 modern directors: ['Ridley Scott', 'Woody Allen', 'Lasse Hallström', 'Tim Burton', 'Shawn Levy', 'Nicholas Stoller', 'Jon M. Chu', 'Paul W.S. Anderson', 'Clint Eastwood', 'Michael Bay']\n",
      "Top 5 modern actors sample: ['Bruce Willis', 'Bryan Cranston', 'Chris Hemsworth', 'Owen Wilson', 'Toby Kebbell']\n"
     ]
    }
   ],
   "source": [
    "# 4.4  Top modern directors & actors (for datasets with credits)\n",
    "# Computed from meta_credits (largest set with credits data)\n",
    "\n",
    "# --- Top Directors (post-2010) ---\n",
    "dir_year_pairs = []\n",
    "for _, row in df_meta_credits.iterrows():\n",
    "    year = row['release_year']\n",
    "    crew = row['crew_parsed']\n",
    "    if isinstance(crew, list):\n",
    "        for m in crew:\n",
    "            if isinstance(m, dict) and m.get('job') == 'Director' and m.get('name'):\n",
    "                dir_year_pairs.append((m['name'], year))\n",
    "\n",
    "dir_year_df = pd.DataFrame(dir_year_pairs, columns=['director', 'year'])\n",
    "post2010_dirs = dir_year_df[dir_year_df['year'] >= 2010]['director'].value_counts()\n",
    "top_directors = set(post2010_dirs.head(50).index)\n",
    "\n",
    "def has_top_dir(crew):\n",
    "    if not isinstance(crew, list): return 0\n",
    "    for m in crew:\n",
    "        if isinstance(m, dict) and m.get('job') == 'Director':\n",
    "            if m.get('name', '') in top_directors: return 1\n",
    "    return 0\n",
    "\n",
    "# --- Top Actors (post-2010) ---\n",
    "act_data = []\n",
    "for _, row in df_meta_credits.iterrows():\n",
    "    year = row['release_year']\n",
    "    cast = row['cast_parsed']\n",
    "    if isinstance(cast, list):\n",
    "        for m in cast:\n",
    "            if isinstance(m, dict) and m.get('name') and 'order' in m:\n",
    "                act_data.append((m['name'], year, m['order']))\n",
    "\n",
    "act_df = pd.DataFrame(act_data, columns=['actor', 'year', 'order'])\n",
    "post2010_acts = act_df[act_df['year'] >= 2010]\n",
    "top_actors = set(post2010_acts['actor'].value_counts().head(50).index)\n",
    "top_leads = set(post2010_acts[post2010_acts['order'] == 0]['actor'].value_counts().head(50).index)\n",
    "\n",
    "def count_top_actors(cast):\n",
    "    if not isinstance(cast, list): return 0\n",
    "    return sum(1 for m in cast if isinstance(m, dict) and m.get('name', '') in top_actors)\n",
    "\n",
    "def check_top_lead(cast):\n",
    "    if not isinstance(cast, list): return 0\n",
    "    for m in cast:\n",
    "        if isinstance(m, dict) and m.get('order') == 0:\n",
    "            if m.get('name', '') in top_leads: return 1\n",
    "    return 0\n",
    "\n",
    "# Apply to both datasets with credits (meta_credits and all)\n",
    "for df_label, df_ref in [('meta_credits', df_meta_credits), ('all', df_all)]:\n",
    "    df_ref['has_top_director'] = df_ref['crew_parsed'].apply(has_top_dir)\n",
    "    df_ref['has_top_actor'] = df_ref['cast_parsed'].apply(lambda x: 1 if count_top_actors(x) > 0 else 0)\n",
    "    df_ref['top_actor_count'] = df_ref['cast_parsed'].apply(count_top_actors)\n",
    "    df_ref['has_top_lead_actor'] = df_ref['cast_parsed'].apply(check_top_lead)\n",
    "    n_td = df_ref['has_top_director'].sum()\n",
    "    n_ta = df_ref['has_top_actor'].sum()\n",
    "    print(f'{df_label}: has_top_director={n_td}, has_top_actor={n_ta}')\n",
    "\n",
    "print(f'\\nTop 10 modern directors: {post2010_dirs.head(10).index.tolist()}')\n",
    "print(f'Top 5 modern actors sample: {list(top_actors)[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns per dataset:\n",
      "\n",
      "  metadata (5,352 rows x 17 cols):\n",
      "     1. budget\n",
      "     2. id\n",
      "     3. popularity\n",
      "     4. runtime\n",
      "     5. title\n",
      "     6. vote_average\n",
      "     7. vote_count\n",
      "     8. is_collection\n",
      "     9. is_english\n",
      "    10. release_year\n",
      "    11. release_month\n",
      "    12. roi\n",
      "    13. num_genres\n",
      "    14. num_production_companies\n",
      "    15. num_production_countries\n",
      "    16. num_spoken_languages\n",
      "    17. primary_genre\n",
      "\n",
      "  meta_credits (5,352 rows x 23 cols):\n",
      "     1. budget\n",
      "     2. id\n",
      "     3. popularity\n",
      "     4. runtime\n",
      "     5. title\n",
      "     6. vote_average\n",
      "     7. vote_count\n",
      "     8. is_collection\n",
      "     9. is_english\n",
      "    10. release_year\n",
      "    11. release_month\n",
      "    12. roi\n",
      "    13. num_genres\n",
      "    14. num_production_companies\n",
      "    15. num_production_countries\n",
      "    16. num_spoken_languages\n",
      "    17. primary_genre\n",
      "    18. num_cast\n",
      "    19. num_crew\n",
      "    20. has_top_director\n",
      "    21. has_top_actor\n",
      "    22. top_actor_count\n",
      "    23. has_top_lead_actor\n",
      "\n",
      "  meta_keywords (5,352 rows x 18 cols):\n",
      "     1. budget\n",
      "     2. id\n",
      "     3. popularity\n",
      "     4. runtime\n",
      "     5. title\n",
      "     6. vote_average\n",
      "     7. vote_count\n",
      "     8. is_collection\n",
      "     9. is_english\n",
      "    10. release_year\n",
      "    11. release_month\n",
      "    12. roi\n",
      "    13. num_genres\n",
      "    14. num_production_companies\n",
      "    15. num_production_countries\n",
      "    16. num_spoken_languages\n",
      "    17. primary_genre\n",
      "    18. num_keywords\n",
      "\n",
      "  all (5,352 rows x 24 cols):\n",
      "     1. budget\n",
      "     2. id\n",
      "     3. popularity\n",
      "     4. runtime\n",
      "     5. title\n",
      "     6. vote_average\n",
      "     7. vote_count\n",
      "     8. is_collection\n",
      "     9. is_english\n",
      "    10. release_year\n",
      "    11. release_month\n",
      "    12. roi\n",
      "    13. num_genres\n",
      "    14. num_production_companies\n",
      "    15. num_production_countries\n",
      "    16. num_spoken_languages\n",
      "    17. primary_genre\n",
      "    18. num_cast\n",
      "    19. num_crew\n",
      "    20. num_keywords\n",
      "    21. has_top_director\n",
      "    22. has_top_actor\n",
      "    23. top_actor_count\n",
      "    24. has_top_lead_actor\n"
     ]
    }
   ],
   "source": [
    "# 4.5  Drop raw/unused columns from all 4 datasets\n",
    "meta_drop = [\n",
    "    'adult', 'video', 'status',\n",
    "    'belongs_to_collection', 'homepage', 'tagline', 'poster_path',\n",
    "    'imdb_id', 'original_title', 'overview',\n",
    "    'original_language', 'release_date',\n",
    "    'genres', 'production_companies', 'production_countries', 'spoken_languages',\n",
    "]\n",
    "\n",
    "# Dataset 1: Metadata Only\n",
    "df_metadata = df_metadata.drop(columns=[c for c in meta_drop if c in df_metadata.columns])\n",
    "\n",
    "# Dataset 2: Metadata + Credits\n",
    "credits_drop = meta_drop + ['cast_parsed', 'crew_parsed']\n",
    "df_meta_credits = df_meta_credits.drop(columns=[c for c in credits_drop if c in df_meta_credits.columns])\n",
    "\n",
    "# Dataset 3: Metadata + Keywords\n",
    "keywords_drop = meta_drop + ['keywords_parsed']\n",
    "df_meta_keywords = df_meta_keywords.drop(columns=[c for c in keywords_drop if c in df_meta_keywords.columns])\n",
    "\n",
    "# Dataset 4: All Combined\n",
    "all_drop = meta_drop + ['cast_parsed', 'crew_parsed', 'keywords_parsed']\n",
    "df_all = df_all.drop(columns=[c for c in all_drop if c in df_all.columns])\n",
    "\n",
    "print('Columns per dataset:')\n",
    "for name, df_ref in [('metadata', df_metadata), ('meta_credits', df_meta_credits),\n",
    "                      ('meta_keywords', df_meta_keywords), ('all', df_all)]:\n",
    "    print(f'\\n  {name} ({df_ref.shape[0]:,} rows x {df_ref.shape[1]} cols):')\n",
    "    for i, col in enumerate(df_ref.columns, 1):\n",
    "        print(f'    {i:2d}. {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET COMPARISON\n",
      "================================================================================\n",
      "        Dataset  Rows  Columns  Numeric Features  ROI Median  Profitable %\n",
      "  Metadata Only  5352       17                15       106.7          69.9\n",
      " Meta + Credits  5352       23                21       106.7          69.9\n",
      "Meta + Keywords  5352       18                16       106.7          69.9\n",
      "   All Combined  5352       24                22       106.7          69.9\n",
      "\n",
      "--- Missing Values ---\n",
      "Metadata Only: 0 total missing values\n",
      "Meta + Credits: 0 total missing values\n",
      "Meta + Keywords: 0 total missing values\n",
      "All Combined: 0 total missing values\n"
     ]
    }
   ],
   "source": [
    "# 4.6  Dataset comparison overview\n",
    "print('=' * 80)\n",
    "print('DATASET COMPARISON')\n",
    "print('=' * 80)\n",
    "\n",
    "datasets_info = {\n",
    "    'Metadata Only': df_metadata,\n",
    "    'Meta + Credits': df_meta_credits,\n",
    "    'Meta + Keywords': df_meta_keywords,\n",
    "    'All Combined': df_all,\n",
    "}\n",
    "\n",
    "comparison_rows = []\n",
    "for label, df_ref in datasets_info.items():\n",
    "    numeric_df = df_ref.select_dtypes(include=[np.number])\n",
    "    comparison_rows.append({\n",
    "        'Dataset': label,\n",
    "        'Rows': len(df_ref),\n",
    "        'Columns': df_ref.shape[1],\n",
    "        'Numeric Features': numeric_df.shape[1],\n",
    "        'ROI Median': round(df_ref['roi'].median(), 1),\n",
    "        'Profitable %': round((df_ref['roi'] > 0).mean() * 100, 1),\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_rows)\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "# Missing values check\n",
    "print('\\n--- Missing Values ---')\n",
    "for label, df_ref in datasets_info.items():\n",
    "    n_missing = df_ref.isnull().sum().sum()\n",
    "    print(f'{label}: {n_missing} total missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed datasets:\n",
      "  ✓ metadata        → ../data/processed/movies_processed_metadata.csv  (5,352 rows x 17 cols)\n",
      "  ✓ meta_credits    → ../data/processed/movies_processed_meta_credits.csv  (5,352 rows x 23 cols)\n",
      "  ✓ meta_keywords   → ../data/processed/movies_processed_meta_keywords.csv  (5,352 rows x 18 cols)\n",
      "  ✓ all             → ../data/processed/movies_processed.csv  (5,352 rows x 24 cols)\n"
     ]
    }
   ],
   "source": [
    "# 5. Save all 4 processed datasets\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "save_map = {\n",
    "    'metadata':      (df_metadata,      '../data/processed/movies_processed_metadata.csv'),\n",
    "    'meta_credits':  (df_meta_credits,  '../data/processed/movies_processed_meta_credits.csv'),\n",
    "    'meta_keywords': (df_meta_keywords, '../data/processed/movies_processed_meta_keywords.csv'),\n",
    "    'all':           (df_all,           '../data/processed/movies_processed.csv'),\n",
    "}\n",
    "\n",
    "print('Saving processed datasets:')\n",
    "for key, (df_ref, path) in save_map.items():\n",
    "    df_ref.to_csv(path, index=False)\n",
    "    print(f'  ✓ {key:15s} → {path}  ({len(df_ref):,} rows x {df_ref.shape[1]} cols)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### 4 Processed Datasets Created\n",
    "\n",
    "| Dataset | File | Sources |\n",
    "|---|---|---|\n",
    "| Metadata Only | `movies_processed_metadata.csv` | movies_metadata |\n",
    "| Meta + Credits | `movies_processed_meta_credits.csv` | movies_metadata + credits |\n",
    "| Meta + Keywords | `movies_processed_meta_keywords.csv` | movies_metadata + keywords |\n",
    "| All Combined | `movies_processed.csv` | all three |\n",
    "\n",
    "### Features Per Dataset\n",
    "\n",
    "| Feature | Metadata | +Credits | +Keywords | All |\n",
    "|---|:---:|:---:|:---:|:---:|\n",
    "| `budget`, `popularity`, `runtime`, `vote_average`, `vote_count` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `is_collection`, `is_english` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `release_year`, `release_month` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `roi` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `num_genres`, `num_production_*`, `num_spoken_languages` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `primary_genre` | ✓ | ✓ | ✓ | ✓ |\n",
    "| `num_cast`, `num_crew` | | ✓ | | ✓ |\n",
    "| `has_top_director`, `has_top_actor`, `top_actor_count`, `has_top_lead_actor` | | ✓ | | ✓ |\n",
    "| `num_keywords` | | | ✓ | ✓ |\n",
    "\n",
    "### Next Steps\n",
    "- **Notebook 03:** Prepare all 4 datasets for modeling — encode, split, scale, baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
